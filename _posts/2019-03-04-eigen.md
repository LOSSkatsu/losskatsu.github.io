---
title: "고유값(eigenvalue) 고유벡터(eigenvector)의 의미" 
categories:
  - LinearAlgebra
tags:
  - Statistics
  - MachineLearning
use_math: true
toc: true
toc_label: "My Table of Contents"
toc_icon: "cog"
sidebar:
  title: "AI Machine Learning"
  nav: sidebar-contents
---


# 고유값(eigenvalue) 고유벡터(eigenvector)

선형대수는 제가 참 좋아하는 분야입니다. 
그런 선형대수에서 가장 중요한 부분을 꼽으라고 하면, 저는 고유값, 고유벡터의 이해라고 생각합니다. 
고유값, 고유벡터를 이해한다면 선형대수 전체를 관통할 수 있다고 생각하며, 
고유값, 고유벡터를 이해하지 못한다면 선형대수를 이해하지 못했을 가능성이 높다고 생각합니다.  
일반적인 선형대수 책에서 고유값, 고유벡터를 찾으면 다음과 같은 정의을 아주 쉽게 찾아 보실 수 있습니다.  

$$ Ax = \lambda  x$$

람다가 실수 공간에 속할때($\lambda \in R$), 정방행렬(square matrix) $A$의 고유벡터는 영벡터가 아닌 벡터(nonzero vector) $x$이다. 
또한, $\lambda$는 $A$의 고유값이다.
<br />

이 정의가 의미하는 바는 무엇일까요? 아마 교과서적인 정의 만으로는 이해하시기 어려우실 수 있습니다. 
지금부터 저와함께 차근차근 그 의미를 알아보아요.
<br />

먼저 정방행렬 $A$의 의미를 알아봅시다.

## 정방행렬 A의 의미
우리가 알고 있는 행렬에는 여러가지 의미가 있지만, 
고유값, 고유벡터를 논할 때, 정방행렬은 선형변환을 의미합니다. 
그렇다면 선형변환은 무엇일까요? 

## 선형변환의 의미
선형변환은 쉽게 말해서 좌표공간 내에서 일어날 수 있는 모든 변환이라고 생각하시면 편합니다. 
예를 들어, 좌표평면에 벡터 하나가 있다고 가정하면, 
그 벡터를 확대하거나, 축소하거나, 회전시키거나, 반사시키거나 하는 등과 같은 모든 변환이라고 생각합시다. 
물론 엄밀하게 말하면 이는 틀린 설명이라고 할수도 있으나, 초심자입장에서는 이렇게 이해해도 문제 없을 거라고 생각합니다. 

## Ax의 의미
결국 Ax 는 x라는 벡터에 선형변환(A)을 취한 것을 의미합니다. 
벡터 x를 늘리거나 줄이거나 회전시키거나 하는 등 어떤 '변환'을 취한 것이지요.

## '고유', '벡터'의 의미 
고유, 즉 eigen은 어떤 뜻일까요? 
eigen은 독일어 인데, "own", "peculiar to", "characteristic", "individual"이라는 뜻입니다.

벡터를 구성하는 두 가지가 있습니다. 
여러분도 잘 알다시피 '방향(direction)'과 '크기(magnitude)' 가 그것입니다. 
고유벡터란 방향은 변하지 않고 크기만 변하는 것을 의미 합니다. 

## 람다(고유값)의 의미

## 고유값, 고유벡터의 의미 





