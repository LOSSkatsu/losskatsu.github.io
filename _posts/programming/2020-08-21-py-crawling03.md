---
title: "[python] 파이썬 웹 크롤링(3): 본격적인 크롤링" 
categories:
  - programming
tags:
  - programming
use_math: true
toc: true
toc_label: "My Table of Contents"
toc_icon: "cog"
sidebar:
  title: "AI Machine Learning"
  nav: sidebar-contents
---

# 파이썬 웹 크롤링(3): 본격적인 크롤링

**참고 링크**

* [파이썬 웹 크롤링(1): 크롤링의 기본구조와 BeautifulSoup 설치](https://losskatsu.github.io/programming/py-crawling01/)
* [파이썬 웹 크롤링(2): 데이터 파싱하기](https://losskatsu.github.io/programming/py-crawling02/)
* [파이썬 웹 크롤링(3): 본격적인 크롤링](https://losskatsu.github.io/programming/py-crawling03/)

# Chapter3: 본격적인 크롤링의 시작

지금까지는 단 하나의 정적인 페이지들을 크롤링 해보았습니다. 
지금부터는 실제 인터넷 상에 널리 퍼져있는 다수의 웹 사이트와 다수의 페이지들을 크롤링 해보겠습니다. 
크롤링의 핵심은 다수의 사이트들을 넘나들며 재귀적으로 사용하는 것입니다. 
하나의 페이지 내용을 긁어오고, 다른 페이지를 조사하고 또 다시 긁어 옵니다. 
하지만 꼭 그래야만 하는 것은 아니고 하나의 페이지에 모든 정보가 존재한다면 하나의 페이지만 긁어와도 충분합니다. 

## 3.1 하나의 도메인 여행하기

"Six degrees of wikipedia" 라는 말이 있습니다. 
이말은 위키피디아에서 6개의 링크 이내에 모든 컨텐츠가 연결 되어 있다는 뜻입니다. 
이번 단원에서 할 일은 [the Eric Idle page](https://en.wikipedia.org/wiki/Eric_Idle) 에서 링크를 타고 들어가서 
[the Kevin Bacon page](https://en.wikipedia.org/wiki/Kevin_Bacon) 로 이동하는 것입니다. 

