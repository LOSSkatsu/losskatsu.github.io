---
title: "[딥러닝] 딥러닝 기초(3) 몇가지 껄끄러운 문제해결" 
categories:
  - machine-learning
tags:
  - machine-learning
use_math: true
toc: true
toc_label: "My Table of Contents"
toc_icon: "cog"
sidebar:
  title: "AI Machine Learning"
  nav: sidebar-contents
---

# 딥러닝 기초(3) 몇가지 껄끄러운 문제 해결

## 임계치 위치 문제 해결

이번 포스팅에서는 신경망을 사용하는데있어, 몇가지 해결해야하는 문제점들을 다뤄보겠습니다. 
앞에서 임계치는 t라고 했습니다. 이 임계치를 넘느냐 마느냐로 결과값이 달라지는데요. 
아래 그림에서보시면 임계치 기준이 t인데요. 그런데 만약 0이 임계치이면 좀 더 편하지 않을까요? 

<center><img src="/assets/images/ml/dl/basic_dl/deepbasic08.jpg" width="800"></center> 

그래서 우리는 임계치를 t가 아닌 0으로 조정하기 위해 $w_{0}^{*}$를 도입했습니다. 
아래 그림처럼 입력값 -1에 대해 가중치 $w_{0}=t$라고 합시다. 
그러면 $w_{0}t$는 $-1\times t$이므로 $-t$가 됩니다. 
이렇게 하면 인풋변수들의 영향력을 모두 더했을 때 0이 넘어가면 폭발합니다. 
이렇게 임계치는 0이 되었고, 임계치 문제는 해결되었습니다. 

<center><img src="/assets/images/ml/dl/basic_dl/deepbasic09.jpg" width="800"></center> 


## 임계치 곡선 문제 해결

이번에는 임계치 곡선 문제를 해결해보겠습니다. 
사실 현재는 임계치 곡선을 계단함수(step function)로 사용하고 있는데요. 
이 계단함수의 문제점은 수학적으로 계산하기 어려운 부분이 있습니다. 
따라서 스무스한 형태가 선호됩니다. 아래 그림에서 (a)가 아닌 (b)의 형태가 좋겠네요. 

<center><img src="/assets/images/ml/dl/basic_dl/deepbasic10.jpg" width="800"></center> 

그래서 도입된 것이 아래의 시그모이드 함수입니다. 

$$ \frac{1}{1+e^{-\alpha}}$$

이렇게 임계치 곡선 문제도 해결되었습니다. 
앞으로는 계단함수 대신 시그모이드 함수를 사용하도록하겠습니다. 
