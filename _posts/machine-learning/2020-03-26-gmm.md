---
title: "[머신러닝] 가우시안 혼합 모델(Gaussian mixture model) 기초 개념" 
categories:
  - machine-learning
tags:
  - machine-learning
use_math: true
toc: true
toc_label: "My Table of Contents"
toc_icon: "cog"
sidebar:
  title: "AI Machine Learning"
  nav: sidebar-contents
---

# 가우시안 혼합 모델(Gaussian mixture model) 기초 개념

## 가우시안 혼합 모델 정의

> 혼합 모델은 통계학에서 전체 집단안의 하위 집단의 존재를 나타내기 위한 확률 모델이다. 

즉, 가우시안 혼합 모델은 전체 집단의 하위 집단의 [확률분포](https://losskatsu.github.io/statistics/prob-distribution/)가 [가우시안 분포](https://losskatsu.github.io/statistics/normaldist/)를 따르는 경우를 말합니다. 
흔히 정규분포를 가우시안 분포라고도 부르니 혼동 없으시길 바랍니다. 
또한 가우시안 혼합 모델은 비지도학습의 한 종류로, 데이터 클러스터링(clustering)에 사용합니다. 

## 가우시안 혼합 모델 예시

## 우리가 추정해야할 모수

위 그림처럼 전체 집단의 하위 집단이 가우시안 분포 3개라고 가정합니다. 
이 경우, 저희가 추정해야 할 [모수](https://losskatsu.github.io/statistics/population-sample/)는 총 9개 입니다. 하나하나 살펴보죠. 
먼저 분포가 가우시안 분포를 따르는 하위집단 1개만 살펴봅시다. 
가우시안 분포의 경우 모수가 평균($\mu)$, 분산($\sigma$)입니다. 
여기서 하나를 더 추정해야하는데요, 그것은 전체분포에 대한 해당 하위분포의 비율입니다. 
이를 size($\pi$$라고 하는데요, 다른 말로하면 해당 데이터가 해당 하위집단에 속할 확률입니다. 
그럼 정리해서 첫번째 하위집단의 [모수](https://losskatsu.github.io/statistics/population-sample/)는 $(\mu_1, \sigma_1, \pi_1)$ 입니다. 
그럼 자연스럽게 하위집단이 3개이므로, 나머지 두집단의 모수는 $(\mu_2, \sigma_2, \pi_2)$, $(\mu_3, \sigma_3, \pi_3)$가 됩니다. 


## 확률변수 X의 확률밀도함수

그렇다면 위 정보를 토대로 확률변수 X의 확률 밀도 함수를 살펴봅시다. 

$$ p(x) = \sum_{c}\pi_c N(x; \mu_c, \sigma_c)$$

위 식에서 $c$는 $c$번째 집단을 의미합니다. $c=1,2,3$. 
또한 N은 가우시안 분포라는 뜻이구요, $N(x; \mu_c, \sigma_c)$는 평균이 $\mu_c$, 분산이 $\sigma_c$인 가우시안 분포에서 추출한 데이터라는 뜻입니다.




## EM 알고리즘(Expection Maximization Algorithm)

가우시안 혼합 모델에서는 EM 알고리즘이 쓰이는데요, 

## 잠재변수(latent variable)



