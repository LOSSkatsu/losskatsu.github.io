---
title: "[머신러닝] 서포트 벡터 머신(support vector machine) 개념 정리" 
categories:
  - machine-learning
tags:
  - machine-learning
use_math: true
toc: true
toc_label: "My Table of Contents"
toc_icon: "cog"
sidebar:
  title: "AI Machine Learning"
  nav: sidebar-contents
---

# 서포트 벡터 머신(support vector machine) 개념 정리

참고링크
* [회귀분석 복습하기](https://losskatsu.github.io/statistics/simple-regression/)
* [로지스틱 회귀분석 복습하기](https://losskatsu.github.io/statistics/logistic-regression/)
* [서포트 벡터 머신 복습하기](https://losskatsu.github.io/machine-learning/svm/)


## 개요

데이터 셋을 classification 하는 방법에는 여러가지가 있습니다. 
크게 선형(linear)방법과 비선형(nonlinear) 방법이 있는데요. 
선형방법에 대표적인 방법에는 LDA(Linear Discriminant Analysis), 로지스틱회귀분석 등이 있고, 
비선형방법의 대표적인 방법에는 오늘 다룰 서포트 벡터 머신(support vector machine)이 있겠습니다. 
여기서 비선형이란 경계(boundary)가 비선형이라는 말입니다. 
지금부턴 서포트벡터머신을 간단히 svm 이라고 부르겠습니다.

## margin 

margin은 svm에서 핵심적인 개념입니다. 한글로 번역하면 '여백'이라고 해야할까요. 
이 여백이 중요한 이유는 데이터셋을 분리시킬때 집단간 간격이 가능한한 가장 넓어야하기 때문입니다. 
참고로 어떤 데이터 포인트가 경계선에서 가능한 한 멀리있을수록 우리의 확신 정도는 강해집니다. 
만약 어떤 점이 경계선 근처에 있다면 경계선이 바뀔 경우 해당 데이터포인트가 속하는 집단이 달라질 수 있겠죠. 
반면 경계선에서 멀~리 떨어져있다면 경계선이 어떻게 바뀌던 데이터포인트가 속하는 집단이 달라질 가능성은 별로 없습니다. 


